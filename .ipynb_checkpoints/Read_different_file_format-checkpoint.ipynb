{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a17655",
   "metadata": {},
   "source": [
    "# Read most commonly used file formats in Data Science using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae319725",
   "metadata": {},
   "source": [
    "Information is scrapped from this [link](https://www.analyticsvidhya.com/blog/2017/03/read-commonly-used-formats-using-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90d4ce",
   "metadata": {},
   "source": [
    "## .CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c7443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"directory path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ef587",
   "metadata": {},
   "source": [
    "## XLSX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_excel(\"directory path\", sheetname = \"tab sheet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefc7769",
   "metadata": {},
   "source": [
    "## ZIP file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df99dd8a",
   "metadata": {},
   "source": [
    "Importing the “zipfile” package. Below is the python code which can read the “train.csv” file that is inside the “T.zip”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29bdfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "archive = zipfile.ZipFile('T.zip', 'r')\n",
    "df = archive.read('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409c5cc0",
   "metadata": {},
   "source": [
    "## Plain Text (txt) file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07699ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"text.txt\", \"r\")\n",
    "lines = text_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd342d",
   "metadata": {},
   "source": [
    "## JSON file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a0235",
   "metadata": {},
   "source": [
    "The JSON file format can be easily read in any programming language because it is language-independent data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(“/home/kunal/Downloads/Loan_Prediction/train.json”)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d1300",
   "metadata": {},
   "source": [
    "## XML file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1720fa",
   "metadata": {},
   "source": [
    "XML is also known as Extensible Markup Language. As the name suggests, it is a markup language. It has certain rules for encoding data. XML file format is a human-readable and machine-readable file format. XML is a self-descriptive language designed for sending information over the internet. XML is very similar to HTML, but has some differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758f49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('/home/sunilray/Desktop/2 sigma/train.xml')\n",
    "root = tree.getroot()\n",
    "print root.tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21530d3",
   "metadata": {},
   "source": [
    "## HTML files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a86da6",
   "metadata": {},
   "source": [
    "Information is scrapped from [here](https://www.analyticsvidhya.com/blog/2015/10/beginner-guide-web-scraping-beautiful-soup-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44c147a",
   "metadata": {},
   "source": [
    "HTML stands for Hyper Text Markup Language. It is the standard markup language which is used for creating Web pages. HTML is used to describe structure of web pages using markup. HTML tags are same as XML but these are predefined. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1dfb3d",
   "metadata": {},
   "source": [
    "The action to read HTML file is refered to web scrapping. There are 2 x modules for scrapping data:\n",
    " * Urllib2: It is a Python module which can be used for fetching URLs. It defines functions and classes to help with URL actions (basic and digest authentication, redirections, cookies, etc\n",
    " * BeautifulSoup: It is an incredible tool for pulling out information from a webpage. You can use it to extract tables, lists, paragraph and you can also put filters to extract information from web pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b88223",
   "metadata": {},
   "source": [
    "### Basics - Get familiar with HTML tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b248679e",
   "metadata": {},
   "source": [
    "While performing web scarping, we deal with html tags. Thus, we must have good understanding of them. \n",
    "If you already know basics of HTML, you can skip this section. Below is the basic syntax of HTML: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70353cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <body>\n",
    "        <hi1> My First Heading </h1>\n",
    "        <p> My First paragraph </p>\n",
    "    <body>\n",
    "        </html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59863fd",
   "metadata": {},
   "source": [
    "This syntax has various tags as elaborated below:\n",
    "\n",
    "    * <!DOCTYPE html> : HTML documents must start with a type declaration\n",
    "    * HTML document is contained between <html> and </html>\n",
    "    * The visible part of the HTML document is between <body> and </body>\n",
    "    * HTML headings are defined with the <h1> to <h6> tags\n",
    "    * HTML paragraphs are defined with the <p> tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd82cc1",
   "metadata": {},
   "source": [
    "Other useful links\n",
    " 1. HTML links are defined with the <a> tag, “<a href=“http://www.test.com”>This is a link for test.com</a>”\n",
    " 2. HTML tables are defined with<Table>, row as <tr> and rows are divided into data as <td>\n",
    "        <table style = \"width:100%\">\n",
    "    <tr>\n",
    "        <td> Jill <td>\n",
    "        <td> Smith <td>\n",
    "        <td> 50 <td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> Eve <td>\n",
    "        <td> Jackson <td>\n",
    "        <td> 94 <td>\n",
    "    </tr>\n",
    "    </table>\n",
    " 3. HTML list starts with <ul> (unordered) and <ol> (ordered). Each item of list starts with <li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c7b86",
   "metadata": {},
   "source": [
    "### Scrapping a webpage using Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7f9e52",
   "metadata": {},
   "source": [
    "##### 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54928fb7",
   "metadata": {},
   "source": [
    "#import the library used to query a website\n",
    "import urllib.request #if you are using python3+ version, import urllib.request\n",
    "#specify the url\n",
    "wiki = \"https://en.wikipedia.org/wiki/List_of_state_and_union_territory_capitals_in_India\"\n",
    "#Query the website and return the html to the variable 'page'\n",
    "page = urllib2.urlopen(wiki) #For python 3 use urllib.request.urlopen(wiki)\n",
    "#import the Beautiful soup functions to parse the data returned from the website\n",
    "from bs4 import BeautifulSoup\n",
    "#Parse the html in the 'page' variable, and store it in Beautiful Soup format\n",
    "soup = BeautifulSoup(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7f476a",
   "metadata": {},
   "source": [
    "#### 2. Use function \"prettify\" to look at nested structure of HTML page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7893f87",
   "metadata": {},
   "source": [
    "print soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087986de",
   "metadata": {},
   "source": [
    "#### 3. Work with HTML tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3425f747",
   "metadata": {},
   "source": [
    " * soup.<tag> : Return content between opening and closing tag including tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe833c",
   "metadata": {},
   "source": [
    " * soup.<tag>.string : Return string within given tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b4553",
   "metadata": {},
   "outputs": [],
   "source": [
    " * Find all the links within page’s <a> tags::  We know that, we can tag a link using tag “<a>.  \n",
    "So, we should go with option soup.a and it should return the links available in the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2b3860",
   "metadata": {},
   "outputs": [],
   "source": [
    " * Now to extract all the links within <a>, we will use “find_all().e.g soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86aa1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    " * To show only links, we need to iterate over each a tag and return the link uding hte attribute \"href\" with link.get\n",
    "         # all_links = soup.findall(\"a\")\n",
    "         # for link in all_links:\n",
    "         #      print link.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c162a8",
   "metadata": {},
   "outputs": [],
   "source": [
    " * Find the right table\n",
    "         # all_tables = soup.findall('table')\n",
    "Now to identify the right table, we will use attribute “class” of table and use it to filter the right table. \n",
    "In chrome, you can check the class name by right click on the required table of web page \n",
    "–> Inspect element –> Copy the class name OR go through the output of above command find the class name of right table.\n",
    "         # right_table=soup.find('table', class_='wikitable sortable plainrowheaders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d861c730",
   "metadata": {},
   "outputs": [],
   "source": [
    " * Extract the information to DataFrame\n",
    "    Here, we need to iterate through each row (tr) \n",
    "    and then assign each element of tr (td) to a variable and append it to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97bbaba",
   "metadata": {},
   "source": [
    "## Image file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce5e15e",
   "metadata": {},
   "source": [
    "Image files are probably the most fascinating file format used in data science. Any computer vision application is based on image processing. So it is necessary to know different image file formats.\n",
    "\n",
    "Usual image files are 3-Dimensional, having RGB values. But, they can also be 2-Dimensional (grayscale) or 4-Dimensional (having intensity) – an Image consisting of pixels and meta-data associated with it.\n",
    "\n",
    "Each image consists one or more frames of pixels. And each frame is made up of two-dimensional array of pixel values. Pixel values can be of any intensity.  Meta-data associated with an image, can be an image type (.png) or pixel dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a60bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "f = misc.face()\n",
    "misc.imsave('face.png', f) # uses the Image module (PIL)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(f)\n",
    "plt.show()\n",
    "type(f) , f.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6d8d1",
   "metadata": {},
   "source": [
    "## Hierarchical Data Format (HDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d702907",
   "metadata": {},
   "source": [
    "In Hierarchical Data Format ( HDF ), you can store a large amount of data easily. It is not only used for storing high volumes or complex data but also used for storing small volumes or simple data.\n",
    "\n",
    "The advantages of using HDF are as mentioned below:\n",
    "\n",
    "    It can be used in every size and type of system\n",
    "    It has flexible, efficient storage and fast I/O.\n",
    "    Many formats support HDF.\n",
    "\n",
    "There are multiple HDF formats present. But, HDF5 is the latest version which is designed to address some of the limitations of the older HDF file formats. HDF5 format has some similarity with  XML. Like XML, HDF5 files are self-describing and allow users to specify complex data relationships and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b785fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_hdf(‘train.h5’)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7e22af",
   "metadata": {},
   "source": [
    "## PDF file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25cd32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "here exists a library which do a good job in parsing PDF file, one of them is PDFMiner. To read a PDF file through PDFMiner, you have to:\n",
    "    * Install PDFMiner\n",
    "    * pdf2txt.py <pdf_file>.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be6060",
   "metadata": {},
   "source": [
    "## DOCX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05493ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install docx2txt\n",
    "import docx2txt\n",
    "text = docx2txt.process(\"file.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2ca87d",
   "metadata": {},
   "source": [
    "## MP3 file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e501c1f7",
   "metadata": {},
   "source": [
    "## MP4 file format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e04bd",
   "metadata": {},
   "source": [
    "## SQL to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d32b7e",
   "metadata": {},
   "source": [
    "### Create a table with below code with the test_database created in git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aadc087",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_database' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9p/xbvrxvc56yg7hxl3bd1rzrxh0000gn/T/ipykernel_24877/773345352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_database' is not defined"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('test_database') \n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('''\n",
    "          CREATE TABLE IF NOT EXISTS products\n",
    "          ([product_id] INTEGER PRIMARY KEY, [product_name] TEXT, [price] INTEGER)\n",
    "          ''')\n",
    "          \n",
    "c.execute('''\n",
    "          INSERT INTO products (product_id, product_name, price)\n",
    "\n",
    "                VALUES\n",
    "                (1,'Computer',800),\n",
    "                (2,'Printer',200),\n",
    "                (3,'Tablet',300),\n",
    "                (4,'Desk',450),\n",
    "                (5,'Chair',150)\n",
    "          ''')                     \n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d076f23",
   "metadata": {},
   "source": [
    "### Get from SQL to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91dd947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id product_name  price\n",
      "0           1     Computer    800\n",
      "1           2      Printer    200\n",
      "2           3       Tablet    300\n",
      "3           4         Desk    450\n",
      "4           5        Chair    150\n",
      "800\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('test_database') \n",
    "          \n",
    "sql_query = pd.read_sql_query ('''\n",
    "                               SELECT\n",
    "                               *\n",
    "                               FROM products\n",
    "                               ''', conn)\n",
    "\n",
    "df = pd.DataFrame(sql_query, columns = ['product_id', 'product_name', 'price'])\n",
    "print (df)\n",
    "max_price = df.price.max()\n",
    "print(max_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d2521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
